{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-34e672993ece>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting fashion_mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting fashion_mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting fashion_mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting fashion_mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "fashion_mnist = input_data.read_data_sets(\"fashion_mnist/\", one_hot=True)\n",
    "\n",
    "# Python optimisation variables\n",
    "learning_rate = 0.0001\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "# declare the training data placeholders\n",
    "# input x - for 28 x 28 pixels = 784 - this is the flattened image data that is drawn from \n",
    "# fashion_mnist.train.nextbatch()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# dynamically reshape the input\n",
    "x_shaped = tf.reshape(x, [-1, 28, 28, 1])\n",
    "# now declare the output data placeholder - 10 digits\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# loading training and test datasets\n",
    "test= pd.read_csv(\"fashion_mnist/fashion-mnist_test.csv\")\n",
    "train = pd.read_csv(\"fashion_mnist/fashion-mnist_train.csv\")\n",
    "\n",
    "# create training and test labels\n",
    "fashion_train_samples = train.iloc[:,1:]\n",
    "fashion_train_labels = train.iloc[:,0]\n",
    "\n",
    "fashion_test_samples = test.iloc[:,1:]\n",
    "fashion_test_labels = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataset (55000, 784)\n",
      "Shape of test dataset (10000, 784)\n",
      "Shape of validation dataset (5000, 784)\n",
      "Shape of validation dataset (5000, 784)\n",
      "Shape of train labels (55000, 10)\n",
      "Shape of test labels (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train dataset\", fashion_mnist.train.images.shape)\n",
    "print(\"Shape of test dataset\", fashion_mnist.test.images.shape)\n",
    "print(\"Shape of validation dataset\", fashion_mnist.validation.images.shape)\n",
    "print(\"Shape of validation dataset\", fashion_mnist.validation.images.shape)\n",
    "print(\"Shape of train labels\", fashion_mnist.train.labels.shape)\n",
    "print(\"Shape of test labels\", fashion_mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAABvCAYAAABVcfMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample_img = fashionMNIST.train.images[5].reshape(28, 28)\n",
    "sample_img=fashion_train_samples.iloc[6,:].reshape(28,28)\n",
    "plt.subplot(330+7)\n",
    "plt.imshow(sample_img, cmap=plt.get_cmap('gray'))\n",
    "plt.title(fashion_train_labels[6])\n",
    "# plt.show()\n",
    "sample_img=fashion_train_samples.iloc[7,:].reshape(28,28)\n",
    "plt.subplot(330+7+1)\n",
    "plt.imshow(sample_img, cmap=plt.get_cmap('gray'))\n",
    "plt.title(fashion_train_labels[7])\n",
    "sample_img=fashion_train_samples.iloc[8,:].reshape(28,28)\n",
    "plt.subplot(330+8+1)\n",
    "plt.imshow(sample_img, cmap=plt.get_cmap('gray'))\n",
    "plt.title(fashion_train_labels[8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk8kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1137255  0.21960786 0.21960786 0.21960786\n",
      "  0.21960786 0.37254903 0.21960786 0.21960786 0.5882353  0.96470594\n",
      "  0.60784316 0.5529412  0.05490196 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.01176471\n",
      "  0.41176474 0.8235295  0.91372555 0.9960785  0.9960785  0.9960785\n",
      "  0.9960785  0.9960785  0.9960785  0.9960785  0.98823535 0.9607844\n",
      "  0.9960785  0.9960785  0.5764706  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.41176474\n",
      "  0.9960785  0.9960785  0.9686275  0.7411765  0.7411765  0.59607846\n",
      "  0.3529412  0.6666667  0.7411765  0.5647059  0.25490198 0.03529412\n",
      "  0.5529412  0.9960785  0.6431373  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.13725491\n",
      "  0.37647063 0.25882354 0.12156864 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04705883\n",
      "  0.79215693 0.9960785  0.30588236 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.10196079\n",
      "  0.9960785  0.9568628  0.18039216 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.03529412 0.6666667\n",
      "  0.9960785  0.30588236 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.2784314  0.9960785\n",
      "  0.9960785  0.07843138 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.34117648 0.9960785\n",
      "  0.48627454 0.00784314 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02352941 0.79215693 0.9215687\n",
      "  0.07058824 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.44705886 0.9960785  0.6666667\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00784314 0.7725491  0.9921569  0.18823531\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.48627454 0.9960785  0.72156864 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.627451   0.9960785  0.54509807 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01568628 0.8745099  0.9803922  0.24313727 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25490198 0.9960785  0.74509805 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.80392164 0.9960785  0.42352945 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02745098 0.8313726  0.9960785  0.15686275 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20000002 0.9960785  0.9960785  0.30980393 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.5764706  0.9960785  0.54509807 0.00784314 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.43921572 0.9921569  0.227451   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "sample_img = fashion_mnist.train.images[100].reshape(28, 28)\n",
    "plt.imshow(sample_img).set_cmap('Greys')\n",
    "plt.show()\n",
    "print(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_new_conv_layer(input_data, num_input_channels, num_filters, filter_shape, pool_shape, name):\n",
    "    # setup the filter input shape for tf.nn.conv_2d\n",
    "    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,\n",
    "                      num_filters]\n",
    "\n",
    "    # initialise weights and bias for the filter\n",
    "    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),\n",
    "                                      name=name+'_W')\n",
    "    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n",
    "\n",
    "    # setup the convolutional layer operation\n",
    "    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    # add the bias\n",
    "    out_layer += bias\n",
    "\n",
    "    # apply a ReLU non-linear activation\n",
    "    out_layer = tf.nn.relu(out_layer)\n",
    "\n",
    "    # now perform max pooling\n",
    "    ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
    "    strides = [1, 2, 2, 1]\n",
    "    out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides, \n",
    "                               padding='SAME')\n",
    "\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create some convolutional layers\n",
    "layer1 = create_new_conv_layer(x_shaped, 1, 32, [5, 5], [2, 2], name='layer1')\n",
    "layer2 = create_new_conv_layer(layer1, 32, 64, [5, 5], [2, 2], name='layer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened = tf.reshape(layer2, [-1, 7 * 7 * 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup some weights and bias values for this layer, then activate with ReLU\n",
    "wd1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1000], stddev=0.03), name='wd1')\n",
    "bd1 = tf.Variable(tf.truncated_normal([1000], stddev=0.01), name='bd1')\n",
    "dense_layer1 = tf.matmul(flattened, wd1) + bd1\n",
    "dense_layer1 = tf.nn.relu(dense_layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if dataset is correctly read by matching images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# another layer with softmax activations\n",
    "wd2 = tf.Variable(tf.truncated_normal([1000, 10], stddev=0.03), name='wd2')\n",
    "bd2 = tf.Variable(tf.truncated_normal([10], stddev=0.01), name='bd2')\n",
    "dense_layer2 = tf.matmul(dense_layer1, wd2) + bd2\n",
    "y_ = tf.nn.softmax(dense_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocess Dataset\n",
    "Convert to 2D arrays\n",
    "\n",
    "Standardize dataset\n",
    "\n",
    "One-hot encoding of image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=dense_layer2, labels=y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 0.705 test accuracy: 0.942\n",
      "Epoch: 2 cost = 0.153 test accuracy: 0.969\n",
      "Epoch: 3 cost = 0.095 test accuracy: 0.978\n",
      "Epoch: 4 cost = 0.070 test accuracy: 0.980\n",
      "Epoch: 5 cost = 0.055 test accuracy: 0.987\n",
      "Epoch: 6 cost = 0.046 test accuracy: 0.987\n",
      "Epoch: 7 cost = 0.039 test accuracy: 0.989\n",
      "Epoch: 8 cost = 0.033 test accuracy: 0.988\n",
      "Epoch: 9 cost = 0.028 test accuracy: 0.988\n",
      "Epoch: 10 cost = 0.024 test accuracy: 0.988\n",
      "\n",
      "Training complete!\n",
      "0.9875\n"
     ]
    }
   ],
   "source": [
    "# add an optimiser\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# setup the initialisation operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialise the variables\n",
    "    sess.run(init_op)\n",
    "    total_batch = int(len(fashion_mnist.train.labels) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = fashion_mnist.train.next_batch(batch_size=batch_size)\n",
    "            _, c = sess.run([optimiser, cross_entropy], \n",
    "                            feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        test_acc = sess.run(accuracy, \n",
    "                       feed_dict={x: fashion_mnist.test.images, y: fashion_mnist.test.labels})\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost), \"test accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(sess.run(accuracy, feed_dict={x: fashion_mnist.test.images, y: fashion_mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINKS\n",
    "http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/\n",
    "\n",
    "http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
